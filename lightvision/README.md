# LightVision: Lightweight CNNs for Real-World Image Classification

## ğŸ¯ Project Overview

**LightVision** is a comprehensive research project that addresses the critical challenge of deploying accurate image classification models in low-resource environments. While modern deep learning models achieve state-of-the-art performance, they often require substantial computational resources that make them impractical for edge devices, mobile applications, or resource-constrained settings.

This project pioneers an empirical, statistically rigorous comparison of model compression techniquesâ€”knowledge distillation (KD), quantization-aware training (QAT), and pruningâ€”on realistic small-scale datasets. By evaluating these techniques individually and in combination, LightVision provides actionable insights for practitioners deploying vision models in production environments.

## ğŸŒŸ Key Innovations

- **Comprehensive Compression Framework**: Unified evaluation of KD, QAT, and pruning techniques
- **Empirical Rigor**: Statistically rigorous comparisons with multiple runs and significance testing
- **Real-World Datasets**: Evaluation on EuroSAT (RGB) or TrashNet for practical relevance
- **Hardware-Aware Benchmarking**: CPU latency, energy consumption, and model size measurements
- **Deployment Artifacts**: Production-ready models for Raspberry Pi and Android devices
- **Reproducibility-First**: Complete workflow with fixed seeds, versioned datasets, and detailed documentation

## ğŸ“‹ Project Goals

1. **Implement and train** baseline teacher (high-capacity) and student (lightweight) models
2. **Apply compression techniques** including knowledge distillation, QAT, and pruning (structured/unstructured) separately and in combinations
3. **Measure accuracy vs efficiency** trade-offs: model size, FLOPs, CPU latency, and energy consumption
4. **Demonstrate deployment** on target devices (Raspberry Pi or Android via PyTorch Mobile / TFLite)
5. **Produce reproducible artifacts** including code, dataset splits, and a publication-ready report with ablations and statistical tests

## ğŸ—ï¸ Project Structure

```
lightvision/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/              # Data loading and preprocessing
â”‚   â”œâ”€â”€ models/            # Model architectures (teacher, student, compressed)
â”‚   â”œâ”€â”€ training/          # Training scripts and loops
â”‚   â”œâ”€â”€ compression/       # Compression techniques
â”‚   â”‚   â”œâ”€â”€ distillation/  # Knowledge distillation
â”‚   â”‚   â”œâ”€â”€ quantization/  # QAT and post-training quantization
â”‚   â”‚   â””â”€â”€ pruning/       # Structured and unstructured pruning
â”‚   â”œâ”€â”€ evaluation/        # Evaluation metrics and benchmarking
â”‚   â”œâ”€â”€ deployment/        # Deployment utilities and conversion
â”‚   â””â”€â”€ utils/             # Utility functions
â”œâ”€â”€ configs/               # Configuration files (YAML)
â”‚   â”œâ”€â”€ baseline_config.yaml
â”‚   â”œâ”€â”€ distillation_config.yaml
â”‚   â”œâ”€â”€ qat_config.yaml
â”‚   â””â”€â”€ pruning_config.yaml
â”œâ”€â”€ experiments/           # Experiment tracking and results
â”‚   â”œâ”€â”€ baseline/         # Baseline model experiments
â”‚   â”œâ”€â”€ distilled/        # Knowledge distillation experiments
â”‚   â”œâ”€â”€ quantized/        # Quantization experiments
â”‚   â””â”€â”€ pruned/           # Pruning experiments
â”œâ”€â”€ data/                  # Dataset storage
â”‚   â”œâ”€â”€ raw/              # Original datasets
â”‚   â”œâ”€â”€ processed/        # Preprocessed images
â”‚   â””â”€â”€ splits/           # Fixed train/val/test splits
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”‚   â”œâ”€â”€ exploration/      # Data exploration
â”‚   â”œâ”€â”€ analysis/         # Results analysis
â”‚   â””â”€â”€ interpretability/ # Model interpretability
â”œâ”€â”€ tests/                 # Unit and integration tests
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â””â”€â”€ integration/      # Integration tests
â”œâ”€â”€ docs/                  # Documentation
â”‚   â”œâ”€â”€ paper/            # Research paper drafts
â”‚   â”œâ”€â”€ api/              # API documentation
â”‚   â””â”€â”€ deployment/       # Deployment guides
â”œâ”€â”€ scripts/               # Standalone scripts
â”‚   â”œâ”€â”€ preprocessing/    # Data preprocessing
â”‚   â”œâ”€â”€ training/         # Model training
â”‚   â”œâ”€â”€ evaluation/       # Evaluation and benchmarking
â”‚   â””â”€â”€ deployment/       # Deployment scripts
â”œâ”€â”€ outputs/               # Model outputs, logs, plots
â”‚   â”œâ”€â”€ models/           # Trained models
â”‚   â”œâ”€â”€ logs/             # Training logs
â”‚   â”œâ”€â”€ plots/            # Visualizations
â”‚   â””â”€â”€ reports/          # Generated reports
â””â”€â”€ deployment/           # Deployment configurations
    â”œâ”€â”€ raspberry_pi/     # Raspberry Pi deployment
    â””â”€â”€ android/          # Android deployment
```

## ğŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Data Preparation

1. Download dataset (EuroSAT RGB or TrashNet)
2. Run preprocessing pipeline:
```bash
python scripts/preprocessing/prepare_data.py \
    --dataset eurosat \
    --data_dir data/raw \
    --output_dir data/processed \
    --split_seed 42
```

### Training Baseline Teacher Model

```bash
python scripts/training/train_baseline.py \
    --config configs/baseline_config.yaml \
    --model_type teacher \
    --seed 42
```

### Training Student Models

```bash
# Lightweight student model
python scripts/training/train_baseline.py \
    --config configs/baseline_config.yaml \
    --model_type student \
    --seed 42
```

### Model Compression

```bash
# Knowledge Distillation
python scripts/training/train_distilled.py \
    --config configs/distillation_config.yaml \
    --teacher_path outputs/models/teacher_best.pth \
    --seed 42

# Quantization-Aware Training
python scripts/training/train_qat.py \
    --config configs/qat_config.yaml \
    --model_path outputs/models/student_best.pth \
    --seed 42

# Pruning
python scripts/training/train_pruned.py \
    --config configs/pruning_config.yaml \
    --model_path outputs/models/student_best.pth \
    --seed 42

# Combined Pipeline
python scripts/training/train_combined.py \
    --config configs/combined_config.yaml \
    --seed 42
```

### Evaluation and Benchmarking

```bash
# Comprehensive evaluation
python scripts/evaluation/benchmark.py \
    --model_dir outputs/models \
    --test_data data/processed/test \
    --output_dir outputs/reports

# Hardware-specific benchmarking
python scripts/evaluation/benchmark_hardware.py \
    --model_path outputs/models/compressed_model.pth \
    --device raspberry_pi
```

## ğŸ“Š Datasets

### EuroSAT (RGB)
- **Description**: Sentinel-2 satellite images for land use classification
- **Classes**: 10 land use categories
- **Size**: ~27,000 labeled images
- **Image Size**: 64Ã—64 pixels
- **Download**: [EuroSAT Dataset](https://github.com/phelber/EuroSAT)

### TrashNet
- **Description**: Images of recyclable materials for waste classification
- **Classes**: 6 material categories
- **Size**: ~2,500 images
- **Image Size**: Variable (resized to 224Ã—224)
- **Download**: [TrashNet Dataset](https://github.com/garythung/trashnet)

## ğŸ”¬ Research Contributions

This project contributes to the field through:

1. **Empirical Comparison**: Rigorous statistical comparison of compression techniques on realistic datasets
2. **Combined Strategies**: Novel evaluation of combined compression pipelines
3. **Hardware Benchmarks**: Real-world deployment metrics (latency, energy, model size)
4. **Reproducibility**: Complete workflow with fixed seeds and versioned artifacts
5. **Practical Insights**: Actionable recommendations for practitioners

## ğŸ“ Expected Deliverables

- âœ… Trained teacher and student models (baseline and compressed)
- âœ… Comprehensive comparison tables (accuracy, FLOPs, model size, latency, energy)
- âœ… Statistical analysis with significance tests
- âœ… Ablation studies on compression techniques
- âœ… Deployment artifacts (ONNX, TFLite, PyTorch Mobile)
- âœ… Publication-ready technical report (6-8 pages)
- âœ… Reproducibility package (code, configs, dataset splits)

## ğŸ“ Publication Readiness

This project is designed to produce a high-impact publication with:

- **Novel Contributions**: Empirical comparison of compression techniques on small-scale datasets
- **Statistical Rigor**: Multiple runs, significance testing, confidence intervals
- **Comprehensive Evaluation**: Accuracy, efficiency, and deployment metrics
- **Reproducibility**: Complete codebase with fixed seeds and documentation
- **Practical Relevance**: Real-world datasets and deployment scenarios

## ğŸ¤ Contributing

This is a research project. For questions or contributions, please refer to the implementation guide.

## ğŸ“„ License

[Specify license]

## ğŸ™ Acknowledgments

- EuroSAT and TrashNet dataset creators
- PyTorch and TensorFlow communities
- ONNX Runtime and TFLite teams
- Open-source compression research community

