# MultiSense: Multimodal Deep Learning for Emotion Understanding
# Python 3.10+ required

# Core Deep Learning Frameworks
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
transformers>=4.30.0
tensorflow>=2.13.0  # Optional

# Audio Processing
librosa>=0.10.0
soundfile>=0.12.0
scipy>=1.10.0
numpy>=1.24.0
speechbrain>=0.5.15

# Video Processing
opencv-python>=4.8.0
opencv-contrib-python>=4.8.0
imageio>=2.31.0
imageio-ffmpeg>=0.4.9
decord>=0.6.0  # Video decoding

# Text Processing
nltk>=3.8.0
spacy>=3.6.0
transformers>=4.30.0  # For BERT, RoBERTa
sentence-transformers>=2.2.0

# Multimodal Learning
mmcv>=2.0.0  # Optional, for advanced video processing
pytorchvideo>=0.1.5  # Video models

# Attention and Fusion
einops>=0.7.0  # Tensor operations
timm>=0.9.0  # Vision models

# Explainability & Interpretability
shap>=0.42.0
captum>=0.6.0
grad-cam>=1.4.0

# Experiment Tracking & Versioning
wandb>=0.15.0
mlflow>=2.5.0
dvc>=3.0.0
dvc[s3]>=3.0.0
tensorboard>=2.13.0

# Data Processing
pandas>=2.0.0
scikit-learn>=1.3.0
h5py>=3.9.0
pyarrow>=12.0.0

# Statistical Analysis
scipy>=1.10.0
statsmodels>=0.14.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.14.0
Pillow>=10.0.0

# Testing & Quality
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.7.0
flake8>=6.1.0
mypy>=1.5.0

# Utilities
tqdm>=4.65.0
pyyaml>=6.0
python-dotenv>=1.0.0
joblib>=1.3.0
rich>=13.0.0

# Documentation
sphinx>=7.1.0
sphinx-rtd-theme>=1.3.0

# Jupyter
jupyter>=1.0.0
ipykernel>=6.25.0
notebook>=7.0.0

